
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>K-means clustering (kmeans) &mdash; Orange Documentation v2.7.8</title>
    
    <link rel="stylesheet" href="../../_static/orange.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '2.7.8',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="top" title="Orange Documentation v2.7.8" href="../../index.html" />
    <script type="text/javascript" src="../../_static/copybutton.js"></script>

  </head>
  <body>
	<div id="container">
    <div class="border1"></div>
    <div class="border2"></div>
    <div class="borderv">
        <div id="header">
			<div id="orangeimg"><h1><a href="http://orange.biolab.si"><img src="../../_static/orange-logo-w.png" alt="Orange" /></a></h1></div>

            <div id="cse-search-box" style="height: 22px;"></div>
            <div id="underimg"></div>
        </div>
    </div>
    <div class="border2"></div>
    <div class="border1"></div>

    <div id="main">
        <div class="border1"></div>
        <div class="border2"></div>
        <div class="borderv">
            <div id="maininner">
            <p style="font-size: 32px;">
                This is documentation for Orange 2.7. For the latest documentation, 
                <a href="http://orange.biolab.si/docs">
                see Orange 3</a>.
            </p>
 

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
    <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
           <p><a class="uplink" href="../../index.html">Orange Documentation v2.7.8</a></p>
           <ul>
<li><a class="reference internal" href="#">K-means clustering (<tt class="docutils literal"><span class="pre">kmeans</span></tt>)</a><ul>
<li><a class="reference internal" href="#examples">Examples</a></li>
<li><a class="reference internal" href="#k-means-utility-functions">k-Means Utility Functions</a></li>
</ul>
</li>
</ul>

        </div>
    </div>
    
  <span class="target" id="module-Orange.clustering.kmeans"></span><div class="section" id="k-means-clustering-kmeans">
<h1>K-means clustering (<tt class="docutils literal"><span class="pre">kmeans</span></tt>)<a class="headerlink" href="#k-means-clustering-kmeans" title="Permalink to this headline">¶</a></h1>
<span class="target" id="index-0"></span><span class="target" id="index-1"></span><dl class="class">
<dt id="Orange.clustering.kmeans.Clustering">
<em class="property">class </em><tt class="descclassname">Orange.clustering.kmeans.</tt><tt class="descname">Clustering</tt><big>(</big><em>data=None</em>, <em>centroids=3</em>, <em>maxiters=None</em>, <em>minscorechange=None</em>, <em>stopchanges=0</em>, <em>nstart=1</em>, <em>initialization=init_random</em>, <em>distance=Orange.distance.Euclidean</em>, <em>scoring=score_distance_to_centroids</em>, <em>inner_callback=None</em>, <em>outer_callback=None</em><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.Clustering" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements a k-means clustering algorithm:</p>
<ol class="arabic simple">
<li>Choose the number of clusters, k.</li>
<li>Choose a set of k initial centroids.</li>
<li>Assign each instances in the data set to the closest centroid.</li>
<li>For each cluster, compute a new centroid as a center of clustered 
data instances.</li>
<li>Repeat the previous two steps, until some convergence criterion is 
met (e.g., the cluster assignment has not changed).</li>
</ol>
<p>The main advantages of this algorithm are simplicity and low memory  
requirements. The principal disadvantage is the dependence of results 
on the selection of initial set of centroids.</p>
<dl class="attribute">
<dt id="Orange.clustering.kmeans.Clustering.k">
<tt class="descname">k</tt><a class="headerlink" href="#Orange.clustering.kmeans.Clustering.k" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of clusters.</p>
</dd></dl>

<dl class="attribute">
<dt id="Orange.clustering.kmeans.Clustering.data">
<tt class="descname">data</tt><a class="headerlink" href="#Orange.clustering.kmeans.Clustering.data" title="Permalink to this definition">¶</a></dt>
<dd><p>Instances to cluster.</p>
</dd></dl>

<dl class="attribute">
<dt id="Orange.clustering.kmeans.Clustering.centroids">
<tt class="descname">centroids</tt><a class="headerlink" href="#Orange.clustering.kmeans.Clustering.centroids" title="Permalink to this definition">¶</a></dt>
<dd><p>Current set of centroids.</p>
</dd></dl>

<dl class="attribute">
<dt id="Orange.clustering.kmeans.Clustering.scoring">
<tt class="descname">scoring</tt><a class="headerlink" href="#Orange.clustering.kmeans.Clustering.scoring" title="Permalink to this definition">¶</a></dt>
<dd><p>Current clustering score.</p>
</dd></dl>

<dl class="attribute">
<dt id="Orange.clustering.kmeans.Clustering.iteration">
<tt class="descname">iteration</tt><a class="headerlink" href="#Orange.clustering.kmeans.Clustering.iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Current clustering iteration.</p>
</dd></dl>

<dl class="attribute">
<dt id="Orange.clustering.kmeans.Clustering.clusters">
<tt class="descname">clusters</tt><a class="headerlink" href="#Orange.clustering.kmeans.Clustering.clusters" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of cluster indexes. An i-th element provides an
index to a centroid associated with i-th data instance from the input 
data set.</p>
</dd></dl>

<dl class="method">
<dt id="Orange.clustering.kmeans.Clustering.__init__">
<tt class="descname">__init__</tt><big>(</big><em>data=None</em>, <em>centroids=3</em>, <em>maxiters=None</em>, <em>minscorechange=None</em>, <em>stopchanges=0</em>, <em>nstart=1</em>, <em>initialization=init_random</em>, <em>distance=Orange.distance.Euclidean</em>, <em>scoring=score_distance_to_centroids</em>, <em>inner_callback=None</em>, <em>outer_callback=None</em><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.Clustering.__init__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<a class="reference internal" href="Orange.data.table.html#Orange.data.Table" title="Orange.data.Table"><tt class="xref py py-class docutils literal"><span class="pre">Table</span></tt></a> or None) &#8211; Data instances to be clustered. If not None, clustering will be executed immediately after initialization unless <tt class="docutils literal"><span class="pre">initialize_only=True</span></tt>.</li>
<li><strong>centroids</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><tt class="xref py py-obj docutils literal"><span class="pre">int</span></tt></a> or <a class="reference external" href="http://docs.python.org/library/functions.html#list" title="(in Python v2.7)"><tt class="xref py py-obj docutils literal"><span class="pre">list</span></tt></a> of <a class="reference internal" href="Orange.data.instance.html#Orange.data.Instance" title="Orange.data.Instance"><tt class="xref py py-class docutils literal"><span class="pre">Instance</span></tt></a>) &#8211; either specify a number of clusters or provide a list of examples that will serve as clustering centroids.</li>
<li><strong>nstart</strong> (<a class="reference external" href="http://docs.python.org/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; If greater than one, nstart runs of the clustering algorithm will be executed, returning the clustering with the best (lowest) score.</li>
<li><strong>distance</strong> (<a class="reference internal" href="Orange.distance.html#Orange.distance.DistanceConstructor" title="Orange.distance.DistanceConstructor"><tt class="xref py py-class docutils literal"><span class="pre">DistanceConstructor</span></tt></a>) &#8211; an example distance constructor, which measures the distance between two instances.</li>
<li><strong>initialization</strong> &#8211; a function to select centroids given data instances, k and a example distance function. This module implements different approaches (<a class="reference internal" href="#Orange.clustering.kmeans.init_random" title="Orange.clustering.kmeans.init_random"><tt class="xref py py-obj docutils literal"><span class="pre">init_random</span></tt></a>, <a class="reference internal" href="#Orange.clustering.kmeans.init_diversity" title="Orange.clustering.kmeans.init_diversity"><tt class="xref py py-obj docutils literal"><span class="pre">init_diversity</span></tt></a>, <a class="reference internal" href="#Orange.clustering.kmeans.init_hclustering" title="Orange.clustering.kmeans.init_hclustering"><tt class="xref py py-obj docutils literal"><span class="pre">init_hclustering</span></tt></a>).</li>
<li><strong>scoring</strong> &#8211; a function that takes clustering object and returns the clustering score. It could be used, for instance, in procedure that repeats the clustering nstart times, returning the clustering with the lowest score.</li>
<li><strong>inner_callback</strong> &#8211; invoked after every clustering iteration.</li>
<li><strong>outer_callback</strong> &#8211; invoked after every clustering restart (if nstart is greater than 1).</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Stopping criteria:</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>maxiters</strong> (<em>integer</em>) &#8211; maximum number of clustering iterations</li>
<li><strong>minscorechange</strong> (<em>float or None</em>) &#8211; minimal improvement of the score from previous generation (if lower, the clustering will stop). If None, the score will not be computed between iterations</li>
<li><strong>stopchanges</strong> (<em>integer</em>) &#8211; if the number of instances changing the cluster is lower or equal to stopchanges, stop the clustering.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="Orange.clustering.kmeans.Clustering.__call__">
<tt class="descname">__call__</tt><big>(</big><em>data=None</em><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.Clustering.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs the k-means clustering algorithm, with optional new data.</p>
</dd></dl>

<dl class="method">
<dt id="Orange.clustering.kmeans.Clustering.compute_centeroid">
<tt class="descname">compute_centeroid</tt><big>(</big><em>data</em><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.Clustering.compute_centeroid" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a centroid of the data set.</p>
</dd></dl>

<dl class="method">
<dt id="Orange.clustering.kmeans.Clustering.compute_cluster">
<tt class="descname">compute_cluster</tt><big>(</big><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.Clustering.compute_cluster" title="Permalink to this definition">¶</a></dt>
<dd><p>calculate membership in clusters</p>
</dd></dl>

<dl class="method">
<dt id="Orange.clustering.kmeans.Clustering.init_centroids">
<tt class="descname">init_centroids</tt><big>(</big><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.Clustering.init_centroids" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize cluster centroids</p>
</dd></dl>

<dl class="method">
<dt id="Orange.clustering.kmeans.Clustering.run">
<tt class="descname">run</tt><big>(</big><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.Clustering.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs clustering until the convergence conditions are met. If nstart is greater than one, nstart runs of the clustering algorithm will be executed, returning the clustering with the best (lowest) score.</p>
</dd></dl>

<dl class="method">
<dt id="Orange.clustering.kmeans.Clustering.runone">
<tt class="descname">runone</tt><big>(</big><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.Clustering.runone" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs a single clustering iteration, starting with re-computation of centroids, followed by computation of data membership (associating data instances to their nearest centroid).</p>
</dd></dl>

</dd></dl>

<div class="section" id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h2>
<p>The following code runs k-means clustering and prints out the cluster indexes
for the last 10 data instances (<a class="reference download internal" href="../../_downloads/kmeans-run.py"><tt class="xref download docutils literal"><span class="pre">kmeans-run.py</span></tt></a>):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">Orange</span>

<span class="kn">import</span> <span class="nn">random</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">Orange</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Table</span><span class="p">(</span><span class="s">&quot;iris&quot;</span><span class="p">)</span>
<span class="n">km</span> <span class="o">=</span> <span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">Clustering</span><span class="p">(</span><span class="n">iris</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="k">print</span> <span class="n">km</span><span class="o">.</span><span class="n">clusters</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]</span>
</pre></div>
</div>
<p>The output of this code is:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
<p>Invoking a call-back function may be useful when tracing the progress of the clustering.
Below is a code that uses an <tt class="xref py py-obj docutils literal"><span class="pre">inner_callback</span></tt> to report on the number of instances
that have changed the cluster and to report on the clustering score. For the score 
o be computed at each iteration we have to set <tt class="xref py py-obj docutils literal"><span class="pre">minscorechange</span></tt>, but we can
leave it at 0 or even set it to a negative value, which allows the score to deteriorate
by some amount (<a class="reference download internal" href="../../_downloads/kmeans-run-callback.py"><tt class="xref download docutils literal"><span class="pre">kmeans-run-callback.py</span></tt></a>):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">Orange</span>

<span class="kn">import</span> <span class="nn">random</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">callback</span><span class="p">(</span><span class="n">km</span><span class="p">):</span>
    <span class="k">print</span> <span class="s">&quot;Iteration: </span><span class="si">%d</span><span class="s">, changes: </span><span class="si">%d</span><span class="s">, score: </span><span class="si">%.4f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">km</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span> <span class="n">km</span><span class="o">.</span><span class="n">nchanges</span><span class="p">,</span> <span class="n">km</span><span class="o">.</span><span class="n">score</span><span class="p">)</span>
    
<span class="n">iris</span> <span class="o">=</span> <span class="n">Orange</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Table</span><span class="p">(</span><span class="s">&quot;iris&quot;</span><span class="p">)</span>
<span class="n">km</span> <span class="o">=</span> <span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">Clustering</span><span class="p">(</span><span class="n">iris</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">minscorechange</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inner_callback</span><span class="o">=</span><span class="n">callback</span><span class="p">)</span>
</pre></div>
</div>
<p>The convergence on Iris data set is fast:</p>
<div class="highlight-python"><pre>Iteration: 1, changes: 150, score: 10.9555
Iteration: 2, changes: 12, score: 10.3867
Iteration: 3, changes: 2, score: 10.2034
Iteration: 4, changes: 2, score: 10.0699
Iteration: 5, changes: 2, score: 9.9542
Iteration: 6, changes: 1, score: 9.9168
Iteration: 7, changes: 2, score: 9.8624
Iteration: 8, changes: 0, score: 9.8624</pre>
</div>
<p>Call-back above is used for reporting of the progress, but may as well call a function that plots a selection data projection with corresponding centroid at a given step of the clustering. This is exactly what we did with the following script (<a class="reference download internal" href="../../_downloads/kmeans-trace.py"><tt class="xref download docutils literal"><span class="pre">kmeans-trace.py</span></tt></a>):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">random</span>

<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">Orange</span>


<span class="k">def</span> <span class="nf">plot_scatter</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">km</span><span class="p">,</span> <span class="n">attx</span><span class="p">,</span> <span class="n">atty</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s">&quot;kmeans-scatter&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="c">#plot a data scatter plot with the position of centeroids</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s">&#39;figure.figsize&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">]})</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">attx</span><span class="p">])</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">table</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">atty</span><span class="p">])</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">table</span><span class="p">]</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;c&quot;</span><span class="p">,</span> <span class="s">&quot;w&quot;</span><span class="p">,</span> <span class="s">&quot;b&quot;</span><span class="p">]</span>
    <span class="n">cs</span> <span class="o">=</span> <span class="s">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">colors</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">km</span><span class="o">.</span><span class="n">clusters</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">cs</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="n">xc</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">attx</span><span class="p">])</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">km</span><span class="o">.</span><span class="n">centroids</span><span class="p">]</span>
    <span class="n">yc</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="n">atty</span><span class="p">])</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">km</span><span class="o">.</span><span class="n">centroids</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xc</span><span class="p">,</span> <span class="n">yc</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">&quot;x&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">&quot;k&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">attx</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">atty</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">title</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">&quot;</span><span class="si">%s</span><span class="s">-</span><span class="si">%03d</span><span class="s">.png&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">km</span><span class="o">.</span><span class="n">iteration</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">in_callback</span><span class="p">(</span><span class="n">km</span><span class="p">):</span>
    <span class="k">print</span> <span class="s">&quot;Iteration: </span><span class="si">%d</span><span class="s">, changes: </span><span class="si">%d</span><span class="s">, score: </span><span class="si">%8.6f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">km</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span> <span class="n">km</span><span class="o">.</span><span class="n">nchanges</span><span class="p">,</span> <span class="n">km</span><span class="o">.</span><span class="n">score</span><span class="p">)</span>
    <span class="n">plot_scatter</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">km</span><span class="p">,</span> <span class="s">&quot;petal width&quot;</span><span class="p">,</span> <span class="s">&quot;petal length&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&quot;Iteration </span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">km</span><span class="o">.</span><span class="n">iteration</span><span class="p">)</span>
    
<span class="n">table</span> <span class="o">=</span> <span class="n">Orange</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Table</span><span class="p">(</span><span class="s">&quot;iris&quot;</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">km</span> <span class="o">=</span> <span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">Clustering</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">minscorechange</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">maxiters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">inner_callback</span><span class="o">=</span><span class="n">in_callback</span><span class="p">)</span>
</pre></div>
</div>
<p>Only the first four scatterplots are shown below. Colors of the data instances indicate the cluster membership. Notice that since the Iris data set includes four attributes, the closest centroid in a particular 2-dimensional projection is not necessary also the centroid of the cluster that the data point belongs to.</p>
<img alt="../../_images/kmeans-scatter-001.png" src="../../_images/kmeans-scatter-001.png" />
<img alt="../../_images/kmeans-scatter-002.png" src="../../_images/kmeans-scatter-002.png" />
<img alt="../../_images/kmeans-scatter-003.png" src="../../_images/kmeans-scatter-003.png" />
<img alt="../../_images/kmeans-scatter-004.png" src="../../_images/kmeans-scatter-004.png" />
</div>
<div class="section" id="k-means-utility-functions">
<h2>k-Means Utility Functions<a class="headerlink" href="#k-means-utility-functions" title="Permalink to this headline">¶</a></h2>
<dl class="staticmethod">
<dt id="Orange.clustering.kmeans.init_random">
<em class="property">static </em><tt class="descclassname">kmeans.</tt><tt class="descname">init_random</tt><big>(</big><em>data</em>, <em>k</em>, <em>_</em><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.init_random" title="Permalink to this definition">¶</a></dt>
<dd><p>A function that can be used for initialization of k-means clustering returns k data instances from the data. This type of initialization is also known as Fory&#8217;s initialization (Forgy, 1965; He et al., 2004).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<tt class="xref py py-class docutils literal"><span class="pre">orange.ExampleTable</span></tt>) &#8211; data instances.</li>
<li><strong>k</strong> (<em>integer</em>) &#8211; the number of clusters.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="Orange.clustering.kmeans.init_diversity">
<em class="property">static </em><tt class="descclassname">kmeans.</tt><tt class="descname">init_diversity</tt><big>(</big><em>data</em>, <em>k</em>, <em>distfun</em><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.init_diversity" title="Permalink to this definition">¶</a></dt>
<dd><p>A function that can be used for intialization of k-means clustering. Returns a set of centroids where the first one is a data point being the farthest away from the center of the data, and consequent centroids data points of which the minimal distance to the previous set of centroids is maximal. Differs from the initialization proposed by Katsavounidis et al. (1994) only in the selection of the first centroid (where they use a data instance with the highest norm).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<tt class="xref py py-class docutils literal"><span class="pre">orange.ExampleTable</span></tt>) &#8211; data instances.</li>
<li><strong>k</strong> (<em>integer</em>) &#8211; the number of clusters.</li>
<li><strong>distfun</strong> (<a class="reference internal" href="Orange.distance.html#Orange.distance.Distance" title="Orange.distance.Distance"><tt class="xref py py-class docutils literal"><span class="pre">Orange.distance.Distance</span></tt></a>) &#8211; a distance function.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="Orange.clustering.kmeans.init_hclustering">
<em class="property">class </em><tt class="descclassname">Orange.clustering.kmeans.</tt><tt class="descname">init_hclustering</tt><big>(</big><em>n=100</em><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.init_hclustering" title="Permalink to this definition">¶</a></dt>
<dd><p>A class that returns an clustering initialization function that performs
hierarhical clustering, uses it to infer k clusters, and computes a
list of cluster-based data centers</p>
<dl class="method">
<dt id="Orange.clustering.kmeans.init_hclustering.__call__">
<tt class="descname">__call__</tt><big>(</big><em>data</em>, <em>k</em>, <em>disfun</em><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.init_hclustering.__call__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<tt class="xref py py-class docutils literal"><span class="pre">orange.ExampleTable</span></tt>) &#8211; data instances.</li>
<li><strong>k</strong> (<em>integer</em>) &#8211; the number of clusters.</li>
<li><strong>distfun</strong> (<a class="reference internal" href="Orange.distance.html#Orange.distance.Distance" title="Orange.distance.Distance"><tt class="xref py py-class docutils literal"><span class="pre">Orange.distance.Distance</span></tt></a>) &#8211; a distance function.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="Orange.clustering.kmeans.init_hclustering.__init__">
<tt class="descname">__init__</tt><big>(</big><em>n=100</em><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.init_hclustering.__init__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>n</strong> (<em>integer</em>) &#8211; number of data instances to sample.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="staticmethod">
<dt id="Orange.clustering.kmeans.plot_silhouette">
<em class="property">static </em><tt class="descclassname">kmeans.</tt><tt class="descname">plot_silhouette</tt><big>(</big><em>km</em>, <em>filename=tmp.png</em>, <em>fast=False</em><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.plot_silhouette" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves a silhuette plot to filename, showing the distributions of silhouette scores in clusters. kmeans is a k-means clustering object. If fast is True use score_fast_silhouette to compute scores instead of score_silhouette.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>km</strong> (<tt class="xref py py-class docutils literal"><span class="pre">KMeans</span></tt>) &#8211; a k-means clustering object.</li>
<li><strong>filename</strong> (<a class="reference external" href="http://docs.python.org/library/string.html#module-string" title="(in Python v2.7)"><em>string</em></a>) &#8211; name of output plot.</li>
<li><strong>fast</strong> (<em>boolean.</em>) &#8211; if True use <a class="reference internal" href="#Orange.clustering.kmeans.score_fast_silhouette" title="Orange.clustering.kmeans.score_fast_silhouette"><tt class="xref py py-func docutils literal"><span class="pre">score_fast_silhouette()</span></tt></a> to compute scores instead of <a class="reference internal" href="#Orange.clustering.kmeans.score_silhouette" title="Orange.clustering.kmeans.score_silhouette"><tt class="xref py py-func docutils literal"><span class="pre">score_silhouette()</span></tt></a></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="Orange.clustering.kmeans.score_distance_to_centroids">
<em class="property">static </em><tt class="descclassname">kmeans.</tt><tt class="descname">score_distance_to_centroids</tt><big>(</big><em>km</em><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.score_distance_to_centroids" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an average distance of data instances to their associated centroids.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>km</strong> (<tt class="xref py py-class docutils literal"><span class="pre">KMeans</span></tt>) &#8211; a k-means clustering object.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="Orange.clustering.kmeans.score_silhouette">
<em class="property">static </em><tt class="descclassname">kmeans.</tt><tt class="descname">score_silhouette</tt><big>(</big><em>km</em>, <em>index=None</em><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.score_silhouette" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an average silhouette score of data instances.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>km</strong> (<tt class="xref py py-class docutils literal"><span class="pre">KMeans</span></tt>) &#8211; a k-means clustering object.</li>
<li><strong>index</strong> (<em>integer</em>) &#8211; if given, the functon returns just the silhouette score of that particular data instance.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="Orange.clustering.kmeans.score_fast_silhouette">
<em class="property">static </em><tt class="descclassname">kmeans.</tt><tt class="descname">score_fast_silhouette</tt><big>(</big><em>km</em>, <em>index=None</em><big>)</big><a class="headerlink" href="#Orange.clustering.kmeans.score_fast_silhouette" title="Permalink to this definition">¶</a></dt>
<dd><p>Same as score_silhouette, but computes an approximation and is faster.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>km</strong> (<tt class="xref py py-class docutils literal"><span class="pre">KMeans</span></tt>) &#8211; a k-means clustering object.</td>
</tr>
</tbody>
</table>
</dd></dl>

<p>Typically, the choice of seeds has a large impact on the k-means clustering, 
with better initialization methods yielding a clustering that converges faster 
and finds more optimal centroids. The following code compares three different 
initialization methods (random, diversity-based and hierarchical clustering-based) 
in terms of how fast they converge (<a class="reference download internal" href="../../_downloads/kmeans-cmp-init.py"><tt class="xref download docutils literal"><span class="pre">kmeans-cmp-init.py</span></tt></a>):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">Orange</span>

<span class="n">data_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;iris&quot;</span><span class="p">,</span> <span class="s">&quot;housing&quot;</span><span class="p">,</span> <span class="s">&quot;vehicle&quot;</span><span class="p">]</span>
<span class="n">data_sets</span> <span class="o">=</span> <span class="p">[</span><span class="n">Orange</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Table</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">data_names</span><span class="p">]</span>

<span class="k">print</span> <span class="s">&quot;</span><span class="si">%10s</span><span class="s"> </span><span class="si">%3s</span><span class="s"> </span><span class="si">%3s</span><span class="s"> </span><span class="si">%3s</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="s">&quot;&quot;</span><span class="p">,</span> <span class="s">&quot;Rnd&quot;</span><span class="p">,</span> <span class="s">&quot;Div&quot;</span><span class="p">,</span> <span class="s">&quot;HC&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data_sets</span><span class="p">,</span> <span class="n">data_names</span><span class="p">):</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">km_random</span> <span class="o">=</span> <span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">Clustering</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">centroids</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">km_diversity</span> <span class="o">=</span> <span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">Clustering</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">centroids</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">initialization</span><span class="o">=</span><span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">init_diversity</span><span class="p">)</span>
    <span class="n">km_hc</span> <span class="o">=</span> <span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">Clustering</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">centroids</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">initialization</span><span class="o">=</span><span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">init_hclustering</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
    <span class="k">print</span> <span class="s">&quot;</span><span class="si">%10s</span><span class="s"> </span><span class="si">%3d</span><span class="s"> </span><span class="si">%3d</span><span class="s"> </span><span class="si">%3d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">km_random</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span> <span class="n">km_diversity</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span> <span class="n">km_hc</span><span class="o">.</span><span class="n">iteration</span><span class="p">)</span>
</pre></div>
</div>
<p>As expected, k-means converges faster with diversity and clustering-based 
initialization that with random seed selection:</p>
<div class="highlight-python"><pre>        Rnd Div  HC
   iris  12   3   4
housing  14   6   4
vehicle  11   4   3</pre>
</div>
<p>The following code computes the silhouette score for k=2..7 and plots a 
silhuette plot for k=3 (<a class="reference download internal" href="../../_downloads/kmeans-silhouette.py"><tt class="xref download docutils literal"><span class="pre">kmeans-silhouette.py</span></tt></a>):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">Orange</span>

<span class="n">voting</span> <span class="o">=</span> <span class="n">Orange</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Table</span><span class="p">(</span><span class="s">&quot;voting&quot;</span><span class="p">)</span>
<span class="c"># table = Orange.data.Table(&quot;iris&quot;)</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">):</span>
    <span class="n">km</span> <span class="o">=</span> <span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">Clustering</span><span class="p">(</span><span class="n">voting</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">initialization</span><span class="o">=</span><span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">init_diversity</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">score_silhouette</span><span class="p">(</span><span class="n">km</span><span class="p">)</span>
    <span class="k">print</span> <span class="n">k</span><span class="p">,</span> <span class="n">score</span>

<span class="n">km</span> <span class="o">=</span> <span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">Clustering</span><span class="p">(</span><span class="n">voting</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">initialization</span><span class="o">=</span><span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">init_diversity</span><span class="p">)</span>
<span class="n">Orange</span><span class="o">.</span><span class="n">clustering</span><span class="o">.</span><span class="n">kmeans</span><span class="o">.</span><span class="n">plot_silhouette</span><span class="p">(</span><span class="n">km</span><span class="p">,</span> <span class="s">&quot;kmeans-silhouette.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The analysis suggests that k=2 is preferred as it yields
the maximal silhouette coefficient:</p>
<div class="highlight-python"><pre>2 0.629467553352
3 0.504318855054
4 0.407259377854
5 0.358628975081
6 0.353228492088
7 0.366357876944</pre>
</div>
<div class="figure">
<img alt="../../_images/kmeans-silhouette.png" src="../../_images/kmeans-silhouette.png" />
<p class="caption">Silhouette plot for k=3.</p>
</div>
</div>
</div>



          </div>
        </div>
      </div> 
      <div class="clearer"></div>
    </div>  
	
    <div class="footer">
    </div>
	            </div>
        </div>
        <div class="border1"></div>
        <div class="border2"></div>
    </div>
</div>

  </body>
</html>